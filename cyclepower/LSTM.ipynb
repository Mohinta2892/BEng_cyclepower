{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_LSTM_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDz_SuP8GwOU",
        "colab_type": "code",
        "outputId": "d393a4bd-0951-49d4-b5f8-b832460ec612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/data2')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1HdRVZ5uOwQW7XlpOyqT43YP94BsYfMv0' in parents\"}).GetList()#{'q': \"'1S02HappJ9ZBnkhLYg-PMMxTTd7HWsGCa' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: rider4_ride9_raw.csv, id: 1MEU4LoBvFwowNcRhdJ32WOzzNMMdbOxC\n",
            "downloading to /root/data2/rider4_ride9_raw.csv\n",
            "title: rider4_ride8_raw.csv, id: 1TFh4oVK_8sY7TlWpR-bzImARBnZdqeO-\n",
            "downloading to /root/data2/rider4_ride8_raw.csv\n",
            "title: rider4_ride7_raw.csv, id: 1ICWGr_CUIQk8aeDAZ-w7byabfKROe4yy\n",
            "downloading to /root/data2/rider4_ride7_raw.csv\n",
            "title: rider4_ride6_raw.csv, id: 1fq4JE7NbxRxYIaw3P6UwNg-Prr97I3Rx\n",
            "downloading to /root/data2/rider4_ride6_raw.csv\n",
            "title: rider4_ride5_raw.csv, id: 1ctam-j3FoX2Ik_QLG7qNZJKtlO5E7zvN\n",
            "downloading to /root/data2/rider4_ride5_raw.csv\n",
            "title: rider4_ride4_raw.csv, id: 1DGDsrJTKiVRWA4B2uNm4Jmhlvgre4r3T\n",
            "downloading to /root/data2/rider4_ride4_raw.csv\n",
            "title: rider4_ride3_raw.csv, id: 1mf7mduKtuFRCDCzeLg9V32Ci0qudUFGq\n",
            "downloading to /root/data2/rider4_ride3_raw.csv\n",
            "title: rider4_ride2_raw.csv, id: 1vwGV4GpzSeu_RxMUVu6Aro-DVeCeGwq2\n",
            "downloading to /root/data2/rider4_ride2_raw.csv\n",
            "title: rider4_ride1_raw.csv, id: 1LM6Ukc48cibw-7qTOACoQcBWYPo1vrud\n",
            "downloading to /root/data2/rider4_ride1_raw.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOT2TauyG6W8",
        "colab_type": "code",
        "outputId": "9ac74e44-6582-4ce6-cf49-87ae7e7655c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob \n",
        "import copy\n",
        "#tf.compat.v1.enable_eager_execution() \n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "#read csv all data, rename the old files with _old\n",
        "all_files = glob.glob(\"//root//data2//*raw.csv\")\n",
        "test_files = glob.glob(\"//root//data2//*old.csv\")\n",
        "\n",
        "#read csv rider wise, rename the test file as test_ and keep the rider files as is\n",
        "#all_files = glob.glob(\"//root//data2//rider*.csv\")\n",
        "#test_files = glob.glob(\"//root//data2//test*.csv\")\n",
        "\n",
        "li=[]\n",
        "for filename in all_files:\n",
        "    print('importing...',filename)\n",
        "    df1 = pd.read_csv(filename, index_col=None, header=0)\n",
        "    print('before drop',len(df1))\n",
        "    df1.replace(r\"^\\s*$\",np.nan,inplace=True, regex=True)\n",
        "    df1.replace(r\"^\\s*true$\",1,inplace=True, regex=True)\n",
        "    df1.replace(r\"^\\s*false$\",0,inplace=True, regex=True)\n",
        "    df1.dropna(axis=0,how='any',inplace=True)\n",
        "    print('after drop',len(df1))\n",
        "    li.append(df1)\n",
        "\n",
        "df = pd.concat(li, axis=0, ignore_index=True)\n",
        "total_trn = len(df)\n",
        "print('total_train',len(df))\n",
        "\n",
        "li1=[]\n",
        "for filename in test_files:\n",
        "  print('importing...',filename)\n",
        "  df1=pd.read_csv(filename, index_col=None, header=0)\n",
        "  #df1[['cadence','altitude_smooth','grade_smooth','velocity_smooth','watts']].str.strip()\n",
        "  print('before drop1',len(df1))\n",
        "  df1.replace(r\"^\\s*$\",np.nan,inplace=True, regex=True)\n",
        "  df1.replace(r\"^\\s*true$\",1,inplace=True, regex=True)\n",
        "  df1.replace(r\"^\\s*false$\",0,inplace=True, regex=True)\n",
        "  #df1.replace(\"\",np.NaN,inplace=True)\n",
        "  #print(df1['watts'].head())\n",
        "  df1.dropna(axis=0,how='any',inplace=True)\n",
        "  #df1.to_csv('new3182519785_dropped.csv')\n",
        "  #files.download('new3182519785_dropped.csv')\n",
        "  print('after drop1',len(df1))\n",
        "  li1.append(df1)\n",
        "\n",
        "test_df = pd.concat(li1, axis=0, ignore_index=True)\n",
        "test_df_copy = copy.deepcopy(test_df)\n",
        "#test_df=test_df.dropna()\n",
        "total_tst = len(test_df)\n",
        "print('total_test',total_tst)\n",
        "#print(test_df['watts'].empty())\n",
        "#test_df_filtered = test_df[test_df['watts'].str.strip()!=np.NaN]\n",
        "print(test_df.tail())\n",
        "#df1 = pd.read_csv('_5.csv')\n",
        "#df=df.append(df1, ignore_index=True)\n",
        "\n",
        "\n",
        "#df=df[['timestamp(s)', 'position_lat(semicircles)', 'position_long(semicircles)', 'gps_accuracy(m)', 'altitude(m)',\n",
        "#       'grade(%)', 'distance(m)', 'cadence(rpm)', 'speed(m/s)', 'power(watts)', 'left_right_balance', 'temperature(C)', 'acceleration']]\n",
        "\n",
        "print (test_df.isnull().any())\n",
        "print(test_df.columns)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing... //root//data2/rider1_ride4_raw.csv\n",
            "before drop 6636\n",
            "after drop 6631\n",
            "importing... //root//data2/rider2_ride1_raw.csv\n",
            "before drop 3221\n",
            "after drop 3221\n",
            "importing... //root//data2/rider2_ride4_raw.csv\n",
            "before drop 4699\n",
            "after drop 4698\n",
            "importing... //root//data2/rider4_ride1_raw.csv\n",
            "before drop 4245\n",
            "after drop 4245\n",
            "importing... //root//data2/rider1_ride3_raw.csv\n",
            "before drop 2316\n",
            "after drop 2312\n",
            "importing... //root//data2/rider2_ride5_raw.csv\n",
            "before drop 4065\n",
            "after drop 4064\n",
            "importing... //root//data2/rider1_ride1_raw.csv\n",
            "before drop 14153\n",
            "after drop 13697\n",
            "importing... //root//data2/rider2_ride2_raw.csv\n",
            "before drop 9572\n",
            "after drop 9555\n",
            "importing... //root//data2/rider2_ride3_raw.csv\n",
            "before drop 7931\n",
            "after drop 7911\n",
            "importing... //root//data2/rider1_ride2_raw.csv\n",
            "before drop 13314\n",
            "after drop 13306\n",
            "total_train 69640\n",
            "importing... //root//data2/rider4_ride3_raw_old.csv\n",
            "before drop1 14204\n",
            "after drop1 14204\n",
            "importing... //root//data2/rider4_ride4_raw_old.csv\n",
            "before drop1 8939\n",
            "after drop1 8939\n",
            "importing... //root//data2/rider4_ride2_raw_old.csv\n",
            "before drop1 7402\n",
            "after drop1 7402\n",
            "importing... //root//data2/rider4_ride8_raw_old.csv\n",
            "before drop1 7284\n",
            "after drop1 7284\n",
            "importing... //root//data2/rider4_ride7_raw_old.csv\n",
            "before drop1 8203\n",
            "after drop1 8203\n",
            "importing... //root//data2/rider4_ride6_raw_old.csv\n",
            "before drop1 7195\n",
            "after drop1 7195\n",
            "importing... //root//data2/rider4_ride5_raw_old.csv\n",
            "before drop1 8649\n",
            "after drop1 8649\n",
            "importing... //root//data2/rider4_ride9_raw_old.csv\n",
            "before drop1 14124\n",
            "after drop1 14124\n",
            "total_test 76000\n",
            "       Unnamed: 0      timestamp(s)  ...  accel_sensor(m2/s)  accel_gps(m2/s)\n",
            "75995       14119  19-05-2019 14.54  ...                0.02         0.000214\n",
            "75996       14120  19-05-2019 14.54  ...               -0.02        -0.005108\n",
            "75997       14121  19-05-2019 14.54  ...                0.41        61.904547\n",
            "75998       14122  19-05-2019 14.54  ...               -1.47       -11.273996\n",
            "75999       14123  19-05-2019 14.54  ...               -3.22       -45.359927\n",
            "\n",
            "[5 rows x 32 columns]\n",
            "Unnamed: 0                    False\n",
            "timestamp(s)                  False\n",
            "position_lat(semicircles)     False\n",
            "position_long(semicircles)    False\n",
            "gps_accuracy(m)               False\n",
            "altitude(m)                   False\n",
            "grade(%)                      False\n",
            "distance(m)                   False\n",
            "cadence(rpm)                  False\n",
            "speed(m/s)                    False\n",
            "left_right_balance            False\n",
            "temperature(C)                False\n",
            "watts                         False\n",
            "acceleration                  False\n",
            "position_lat(degrees)         False\n",
            "position_long(degrees)        False\n",
            "distance_calc(m)              False\n",
            "gps_delta(m)                  False\n",
            "weight_bike_rider_50          False\n",
            "weight_bike_rider_60          False\n",
            "weight_bike_rider_70          False\n",
            "weight_bike_rider_80          False\n",
            "weight_bike_rider_90          False\n",
            "weight_bike_rider_100         False\n",
            "weight_bike_rider_110         False\n",
            "weight_bike_rider_120         False\n",
            "speed_from_sensor(m/s)        False\n",
            "speed_from_gps(m/s)           False\n",
            "wind_resistance_sensor(N)     False\n",
            "wind_resistance_gps(N)        False\n",
            "accel_sensor(m2/s)            False\n",
            "accel_gps(m2/s)               False\n",
            "dtype: bool\n",
            "Index(['Unnamed: 0', 'timestamp(s)', 'position_lat(semicircles)',\n",
            "       'position_long(semicircles)', 'gps_accuracy(m)', 'altitude(m)',\n",
            "       'grade(%)', 'distance(m)', 'cadence(rpm)', 'speed(m/s)',\n",
            "       'left_right_balance', 'temperature(C)', 'watts', 'acceleration',\n",
            "       'position_lat(degrees)', 'position_long(degrees)', 'distance_calc(m)',\n",
            "       'gps_delta(m)', 'weight_bike_rider_50', 'weight_bike_rider_60',\n",
            "       'weight_bike_rider_70', 'weight_bike_rider_80', 'weight_bike_rider_90',\n",
            "       'weight_bike_rider_100', 'weight_bike_rider_110',\n",
            "       'weight_bike_rider_120', 'speed_from_sensor(m/s)',\n",
            "       'speed_from_gps(m/s)', 'wind_resistance_sensor(N)',\n",
            "       'wind_resistance_gps(N)', 'accel_sensor(m2/s)', 'accel_gps(m2/s)'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU9OhrdgHU3T",
        "colab_type": "code",
        "outputId": "a9d60ff5-daee-477c-ce12-a471a36923ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "#total_train 9770,8458,12962,22035\n",
        "#total_test 2210,1354,2814,4707\n",
        "#total_train 29315,25385,38893,66121\n",
        "#total_test 6631,4064,8444,14124\n",
        "#total_train 2930,,,6608\n",
        "#total_test 663,,,1412\n",
        "EVALUATION_INTERVAL = 5000 # How many records you wish to pass in each epoch interval goes here, range can >0 to <= training data set row count\n",
        "EPOCHS = 30 #how many times do you want to iterate\n",
        "TRAIN_SPLIT =  total_trn \n",
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE=32\n",
        "\n",
        "#multivariate data\n",
        "\n",
        "#minimal and extended feature headers. if you normalize and then use the data, remove weight from features, because it is a column of constants and will break the model.\n",
        "\n",
        "# for all files, make sure you have the same no. of cols in old and new and in same order\n",
        "\n",
        "header_sensor_minimal_new = ['distance','speed_from_sensor(m/s)','accel_sensor(m2/s)','grade_smooth','watts']#'weight_bike_rider_80',\n",
        "header_gps_minimal_new = ['distance_calc(m)','speed_from_gps(m/s)','accel_gps(m2/s)','grade_smooth','watts']#'weight_bike_rider_80',\n",
        "\n",
        "header_sensor_extended_new = ['distance','speed_from_sensor(m/s)','accel_sensor(m2/s)','grade_smooth','wind_resistance_sensor(N)',\n",
        "                              'temp','cadence','altitude','watts']#'weight_bike_rider_80','heartrate',\n",
        "header_gps_extended_new = ['distance_calc(m)','speed_from_gps(m/s)','accel_gps(m2/s)','grade_smooth','wind_resistance_gps(N)',\n",
        "                           'temp','cadence','altitude','watts']#'weight_bike_rider_80','heartrate',\n",
        "header_sensor_minimal_old = ['distance(m)','speed(m/s)','accel_sensor(m2/s)','grade(%)','watts' ] #,'weight_bike_rider_80'\n",
        "header_gps_minimal_old = ['distance_calc(m)','speed_from_gps(m/s)','accel_gps(m2/s)','grade(%)', 'watts' ]#,'weight_bike_rider_80'\n",
        "\n",
        "header_sensor_extended_old = ['distance(m)','speed(m/s)','accel_sensor(m2/s)','grade(%)','wind_resistance_sensor(N)',\n",
        "                              'temperature(C)','cadence(rpm)','altitude(m)','watts']#'weight_bike_rider_80',\n",
        "header_gps_extended_old = ['distance_calc(m)','speed_from_gps(m/s)','accel_gps(m2/s)','grade(%)','wind_resistance_gps(N)',\n",
        "                           'temperature(C)','cadence(rpm)','altitude(m)','watts']#'weight_bike_rider_80',\n",
        "\n",
        "features_considered = header_sensor_minimal_new # change header here to switch between min and extended, if riderwise then put the same header, if all files put new, then old\n",
        "\n",
        "features = df[features_considered]\n",
        "\n",
        "print(features.head())\n",
        "\n",
        "test_features_considered = header_sensor_minimal_new # change header here to switch between min and extended, if riderwise then put the same header, if all files put new, then old\n",
        "\n",
        "\n",
        "test_features=test_df[test_features_considered]\n",
        "test_features.columns=features_considered \n",
        "\n",
        "print(test_features.tail())\n",
        "\n",
        "frames = [features,test_features] \n",
        "features = pd.concat(frames)  \n",
        "features[features_considered] = features[features_considered].astype(float) \n",
        "\n",
        "index1 = total_trn - 13306  # switch on when all files - last fle of rider\n",
        "index2 = total_trn + 14204  # switch on when all files - first file of rider 4\n",
        "train1 = features.iloc[:index1,:] # switch on when all files\n",
        "test = features.iloc[index1:index2, :] # switch on when all files\n",
        "train2 = features.iloc[index2:,:]# switch on when all files\n",
        "frames2 = [train1,train2,test] # switch on when all files - used when all data\n",
        "features = pd.concat(frames2)  # switch on when all files - used when all data\n",
        "\n",
        "total_tst = len(test)\n",
        "print(total_tst)\n",
        "\n",
        "\n",
        "print(features.head())\n",
        "print(features.tail())\n",
        "print('total dataset',len(features))\n",
        "\n",
        "\n",
        "#print(features[~features.applymap(np.isreal).all(1)])\n",
        "#plotting individual graphs for features\n",
        "#features.plot(subplots=True)\n",
        "#plt.legend(loc=1)\n",
        "#plt.savefig('features_plot.png')\n",
        "#files.download(\"features_plot.png\") \n",
        "\n",
        "#plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   distance  speed_from_sensor(m/s)  accel_sensor(m2/s)  grade_smooth watts\n",
            "0      20.8                     8.8                 6.6           0.0   286\n",
            "1      30.6                     9.8                 1.0           0.6   268\n",
            "2      39.0                     8.4                -1.4           0.0   258\n",
            "3      47.4                     8.4                 0.0           0.0   269\n",
            "4      57.7                    10.3                 1.9           0.0   275\n",
            "      distance  speed_from_sensor(m/s)  accel_sensor(m2/s)  grade_smooth  watts\n",
            "6626   58590.4                     9.7                 0.3          -0.5    266\n",
            "6627   58599.9                     9.5                -0.2          -0.8    230\n",
            "6628   58609.4                     9.5                 0.0          -1.4    147\n",
            "6629   58618.6                     9.2                -0.3          -1.5     76\n",
            "6630   58627.4                     8.8                -0.4          -1.7     54\n",
            "   distance  speed_from_sensor(m/s)  accel_sensor(m2/s)  grade_smooth  watts\n",
            "0      20.8                     8.8                 6.6           0.0  286.0\n",
            "1      30.6                     9.8                 1.0           0.6  268.0\n",
            "2      39.0                     8.4                -1.4           0.0  258.0\n",
            "3      47.4                     8.4                 0.0           0.0  269.0\n",
            "4      57.7                    10.3                 1.9           0.0  275.0\n",
            "      distance  speed_from_sensor(m/s)  accel_sensor(m2/s)  grade_smooth  watts\n",
            "6626   58590.4                     9.7                 0.3          -0.5  266.0\n",
            "6627   58599.9                     9.5                -0.2          -0.8  230.0\n",
            "6628   58609.4                     9.5                 0.0          -1.4  147.0\n",
            "6629   58618.6                     9.2                -0.3          -1.5   76.0\n",
            "6630   58627.4                     8.8                -0.4          -1.7   54.0\n",
            "total dataset 35946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zWhl-191h5d",
        "colab_type": "code",
        "outputId": "0c678e03-a737-4b88-9021-6f59af4c5691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#TRAIN_SPLIT = len(train1)+len(train2) # used when all file\n",
        "#print(TRAIN_SPLIT)\n",
        "\n",
        "dataset = features.values.astype('float')\n",
        "\n",
        "#data normalization\n",
        "\n",
        "data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\n",
        "data_std = dataset[:TRAIN_SPLIT].std(axis=0)\n",
        "#print(data_mean)\n",
        "#print(data_std)\n",
        "dataset = (dataset-data_mean)/data_std\n",
        "\n",
        "#data standardization\n",
        "#min = dataset[:TRAIN_SPLIT].min()\n",
        "#max = dataset[:TRAIN_SPLIT].max()\n",
        "#dataset = (dataset-min)/(max-min)\n",
        "\n",
        "\n",
        "\n",
        "#download normalized dataset\n",
        "#dataset.to_csv('normalized_dataset.csv')\n",
        "#files.download('normalized_dataset.csv')\n",
        "\n",
        "#single step prediction\n",
        "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
        "                      target_size, step, single_step=False): #dataset, power, 0, 8000, 20, 0, 0, True\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "  for i in range(start_index, end_index): # 20, 8000 for val : 8000 to 10000\n",
        "    indices = range(i-history_size, i, step) # 20-20=0, 20, 1 = [0 to 20, with step 1], for val : 7980  to 8000 with step 1\n",
        "    data.append(dataset[indices]) # 20 x 1 D array\n",
        "\n",
        "    if single_step:\n",
        "      labels.append(target[i+target_size]) # 20+0=20 target[20] val: target[8000]\n",
        "    else:\n",
        "      labels.append(target[i:i+target_size])\n",
        "\n",
        "  return np.array(data), np.array(labels)\n",
        "\n",
        "past_history = 20\n",
        "future_target = 0\n",
        "STEP = 1\n",
        "\n",
        "x_train_single, y_train_single = multivariate_data(dataset, dataset[:, -1], 0,\n",
        "                                                   TRAIN_SPLIT, past_history,\n",
        "                                                   future_target, STEP,\n",
        "                                                   single_step=True)\n",
        "x_val_single, y_val_single = multivariate_data(dataset, dataset[:, -1],\n",
        "                                               TRAIN_SPLIT, None, past_history,\n",
        "                                               future_target, STEP,\n",
        "                                               single_step=True)\n",
        "\n",
        "\n",
        "train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single, y_train_single))\n",
        "#i=0\n",
        "#for element in train_data_single: \n",
        "#  i+=1\n",
        "#print(i)\n",
        "\n",
        "train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat() #.shuffle(BUFFER_SIZE).\n",
        "#i=0\n",
        "#for element in train_data_single: \n",
        "#  print(element)\n",
        "#  i+=1\n",
        "#  if i ==1:\n",
        "#    break\n",
        "\n",
        "\n",
        "val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single, y_val_single))\n",
        "val_data_single = val_data_single.batch(BATCH_SIZE).repeat() \n",
        "\n",
        "#i=0\n",
        "#for element in val_data_single: \n",
        "#  i+=1\n",
        "#  print(element)\n",
        "#  if i==1:\n",
        "#    break\n",
        "#print(i)\n",
        "\n",
        "single_step_model = tf.keras.models.Sequential()\n",
        "single_step_model.add(tf.keras.layers.LSTM(32,\n",
        "                                           input_shape=x_train_single.shape[-2:]))\n",
        "single_step_model.add(tf.keras.layers.Dense(1))\n",
        "#adam=tf.keras.optimizers.Adam(\n",
        "#    learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "#   name='Adam')#, **kwargs)\n",
        "\n",
        "single_step_model.compile(optimizer='Adam', loss='mae') #tf.keras.optimizers.RMSprop()\n",
        "\n",
        "single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,\n",
        "                                            steps_per_epoch=EVALUATION_INTERVAL)\n",
        "                                            #validation_data=val_data_single,  #turn on when want to validate while training\n",
        "                                            #validation_steps=10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "5000/5000 [==============================] - 22s 4ms/step - loss: 0.2472\n",
            "Epoch 2/30\n",
            "5000/5000 [==============================] - 22s 4ms/step - loss: 0.2276\n",
            "Epoch 3/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2256\n",
            "Epoch 4/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2229\n",
            "Epoch 5/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2220\n",
            "Epoch 6/30\n",
            "5000/5000 [==============================] - 22s 4ms/step - loss: 0.2192\n",
            "Epoch 7/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2177\n",
            "Epoch 8/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2155\n",
            "Epoch 9/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2138\n",
            "Epoch 10/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2117\n",
            "Epoch 11/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2101\n",
            "Epoch 12/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2089\n",
            "Epoch 13/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2068\n",
            "Epoch 14/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2060\n",
            "Epoch 15/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2041\n",
            "Epoch 16/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2036\n",
            "Epoch 17/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2018\n",
            "Epoch 18/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2011\n",
            "Epoch 19/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.1999\n",
            "Epoch 20/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.1993\n",
            "Epoch 21/30\n",
            "5000/5000 [==============================] - 22s 4ms/step - loss: 0.1979\n",
            "Epoch 22/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.1968\n",
            "Epoch 23/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.1959\n",
            "Epoch 24/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.1956\n",
            "Epoch 25/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.1944\n",
            "Epoch 26/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.1936\n",
            "Epoch 27/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.1929\n",
            "Epoch 28/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.1923\n",
            "Epoch 29/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.1917\n",
            "Epoch 30/30\n",
            "5000/5000 [==============================] - 21s 4ms/step - loss: 0.1910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC9u3PbvHefe",
        "colab_type": "code",
        "outputId": "d87101b6-c019-40d4-90a9-5365d9ea5c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "def plot_train_history(history, title):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(loss))\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  plt.title(title)\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "#plot_train_history(single_step_history,'Single Step Training and validation loss')\n",
        "\n",
        "#print('Error RMSE : ', tf.sqrt(tf.reduce_mean((y_val_single - single_step_model.predict(x_val_single))**2)))\n",
        "\n",
        "\n",
        "allrmse=[]\n",
        "allmae=[]\n",
        "c=0\n",
        "yhatlist=[]\n",
        "ylist=[]\n",
        "for x, y in val_data_single.take((total_tst-20)//32):\n",
        "  #print(y.shape)\n",
        "  #print(x.shape)\n",
        "  #print('Error RMSE : ', tf.sqrt(tf.reduce_mean((y[0].numpy() - single_step_model.predict(x)[0])**2)))\n",
        "  #Y=round(y[0].numpy(),3)\n",
        "  #Yhat=round(single_step_model.predict(x)[0][0],3)\n",
        "  #YPower = (Y*data_std[-1])+data_mean[-1]\n",
        "  #Yhatpower = (Yhat*data_std[-1])+data_mean[-1]\n",
        "  \n",
        "  #print('y: ', y[0].numpy(), YPower)\n",
        "  #print('yhat: ', single_step_model.predict(x)[0], Yhatpower)\n",
        "  #plot = show_plot([x[0][:, -1].numpy(), y[0].numpy(), # this can be switched on to plot\n",
        "  #                 single_step_model.predict(x)[0]], 0,\n",
        "  #              'Single Step Prediction',Y,Yhat)\n",
        "  #plt.savefig('Lstm_'+str(c)+'.png')\n",
        "  #files.download('Lstm_'+str(c)+'.png')\n",
        "  c+=1\n",
        "  print(c)\n",
        "  #plot.show()\n",
        "  rmse=[]\n",
        "  mae =[]\n",
        "\n",
        "  for j in range(0,len(y)):\n",
        "    '''ylist.append(((y[j].numpy()*data_std[-1])+data_mean[-1]) if ((y[j].numpy()*data_std[-1])+data_mean[-1])>0 else 0)\n",
        "    yhatlist.append(((single_step_model.predict(x)[j][0]*data_std[-1])+data_mean[-1]) if ((single_step_model.predict(x)[j][0]*data_std[-1])+data_mean[-1])>0 else 0 )\n",
        "    rmse.append(tf.sqrt(tf.reduce_mean((y[j].numpy() - single_step_model.predict(x)[j])**2)))#.numpy())'''\n",
        "    ylist.append((y[j].numpy()*data_std[-1])+data_mean[-1])\n",
        "    #ylist.append(y[j].numpy())\n",
        "    #print(y[j].numpy(),single_step_model.predict(x)[j],(y[j].numpy() - (single_step_model.predict(x)[j])))\n",
        "    yhatlist.append((single_step_model.predict(x)[j][0]*data_std[-1])+data_mean[-1])\n",
        "    #yhatlist.append(single_step_model.predict(x)[j][0])\n",
        "    #rmse.append(tf.sqrt(tf.reduce_mean((y[j].numpy() - single_step_model.predict(x)[j][0])**2)))#.numpy())\n",
        "    #rmse.append(metrics.mean_squared_error(y[j].numpy(),single_step_model.predict(x)[j][0],squared=False))\n",
        "    #mae.append(metrics.mean_absolute_error(y[j].numpy(),single_step_model.predict(x)[j][0]))\n",
        "\n",
        "  #print(rmse)\n",
        "  #print(np.mean(rmse))\n",
        "  #allrmse.append(np.mean(rmse))\n",
        "  #allmae.append(np.mean(mae))\n",
        "print('RMSE: ',metrics.mean_squared_error(ylist,yhatlist,squared=False))\n",
        "print('MAE: ',metrics.mean_absolute_error(ylist,yhatlist))\n",
        "print('Mean y_pred_lstm', np.mean(yhatlist))\n",
        "print('MEan ytest', np.mean(ylist))\n",
        "df2=pd.DataFrame({'ytest':ylist, 'yhat':yhatlist})\n",
        "#df2.to_csv('pred_lstm.csv')\n",
        "#print(len(all))\n",
        "#single_step_model.save('rider4_timed3_header_sensor_minimal_old.h5')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "RMSE:  33.745240511303976\n",
            "MAE:  20.99031058293732\n",
            "Mean y_pred_lstm 168.39454937398529\n",
            "MEan ytest 169.12033436236175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxmdHpTGO1HF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "379a3f9d-1b07-4121-a1db-ef2cc9967bfc"
      },
      "source": [
        "df2.to_csv('pred_lstm.csv')\n",
        "files.download('pred_lstm.csv')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d7488e526c2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred_lstm.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ]
    }
  ]
}